{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f796b99d-8230-4059-8e24-6d54ed28fa88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/02/07/5fd2945356dd839974d3a25de8a142dc37293c21315729a41e775b5f3569/textblob-0.18.0.post0-py3-none-any.whl.metadata\n  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: nltk>=3.8 in /databricks/python3/lib/python3.11/site-packages (from textblob) (3.8.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2022.7.9)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\nDownloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/626.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/626.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.7/626.3 kB\u001B[0m \u001B[31m791.1 kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.4/626.3 kB\u001B[0m \u001B[31m554.7 kB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\n\u001B[2K   \u001B[91m━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.2/626.3 kB\u001B[0m \u001B[31m720.3 kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m112.6/626.3 kB\u001B[0m \u001B[31m651.3 kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m215.0/626.3 kB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m235.5/626.3 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m378.9/626.3 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m532.5/626.3 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m626.3/626.3 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: textblob\nSuccessfully installed textblob-0.18.0.post0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288bf576-8dd6-4429-9d15-4f2ec40220e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from textblob import TextBlob\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Reddit Sentiment & Emotion Analysis\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///tmp/spark-warehouse\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e195c0c8-0950-463a-ba03-743b368fe6ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define UDFs for Sentiment and Emotion Analysis\n",
    "Next, define functions for sentiment polarity (using TextBlob) and emotion detection based on sentiment polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b52cd27-7f83-44c7-93cf-848506e824b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.get_emotion(text)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define UDFs for sentiment and emotion analysis\n",
    "def get_sentiment(text):\n",
    "    if text:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity\n",
    "    return 0.0  # Return 0.0 for empty or null texts\n",
    "\n",
    "def get_emotion(text):\n",
    "    sentiment = get_sentiment(text)\n",
    "    if sentiment > 0.1:\n",
    "        return \"Positive\"\n",
    "    elif sentiment < -0.1:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Register UDFs for sentiment and emotion analysis\n",
    "spark.udf.register(\"get_sentiment\", get_sentiment)\n",
    "spark.udf.register(\"get_emotion\", get_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9415c933-86e0-4340-87cc-fffd72794cf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Data from Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "973dc487-477b-485e-ad32-d322446dc254",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data from the Silver layer (assuming it is stored in Delta format)\n",
    "silver_df = spark.read.format(\"delta\").table(\"big_data_analytics_v.big_data_analytics_sesssion_v.silver_reddit_posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f572c74a-5b62-44b5-be0e-356c8398c8fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Apply Sentiment and Emotion Analy sis  on 'title' and 'description'\n",
    "This part involves applying the sentiment and emotion analysis functions (get_sentiment and get_emotion) to the title and description columns of the Reddit posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb36d4ba-108e-4a7c-a758-b434aec9b513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform sentiment and emotion analysis on 'title' and 'description'\n",
    "transformed_df = silver_df.withColumn(\"title_polarity\", F.expr(\"get_sentiment(title)\")) \\\n",
    "                          .withColumn(\"title_emotion\", F.expr(\"get_emotion(title)\")) \\\n",
    "                          .withColumn(\"description_polarity\", F.expr(\"get_sentiment(description)\")) \\\n",
    "                          .withColumn(\"description_emotion\", F.expr(\"get_emotion(description)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9f25b2a-e856-4ccb-9df4-4e1c575b1d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### TF-IDF Feature Extraction\n",
    "This part involves applying the sentiment and emotion analysis functions (get_sentiment and get_emotion) to the title and description columns of the Reddit posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7679a9b6-65a2-4223-9c9f-d70be7697e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace null values in 'title' and 'description' columns with empty strings\n",
    "transformed_df = transformed_df.fillna({'title': '', 'description': ''})\n",
    "\n",
    "# Perform TF-IDF Feature Extraction for 'title' and 'description'\n",
    "tokenizer_title = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "tokenizer_description = Tokenizer(inputCol=\"description\", outputCol=\"description_words\")\n",
    "\n",
    "hashing_tf_title = HashingTF(inputCol=\"title_words\", outputCol=\"title_tfidf\")\n",
    "hashing_tf_description = HashingTF(inputCol=\"description_words\", outputCol=\"description_tfidf\")\n",
    "\n",
    "idf_title = IDF(inputCol=\"title_tfidf\", outputCol=\"title_tfidf_features\")\n",
    "idf_description = IDF(inputCol=\"description_tfidf\", outputCol=\"description_tfidf_features\")\n",
    "\n",
    "# Create a pipeline for TF-IDF feature extraction\n",
    "pipeline = Pipeline(stages=[tokenizer_title, tokenizer_description, hashing_tf_title, \n",
    "                            hashing_tf_description, idf_title, idf_description])\n",
    "\n",
    "# Fit and transform the data to extract features\n",
    "pipeline_model = pipeline.fit(transformed_df)\n",
    "final_df = pipeline_model.transform(transformed_df)\n",
    "\n",
    "# Display the final DataFrame\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f37a4406-e804-49c4-af36-b933435cfa68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- post_id: string (nullable = true)\n |-- title: string (nullable = false)\n |-- description: string (nullable = false)\n |-- subreddit: string (nullable = true)\n |-- author: string (nullable = true)\n |-- score: integer (nullable = true)\n |-- created_at: timestamp (nullable = true)\n |-- url: string (nullable = true)\n |-- title_polarity: string (nullable = true)\n |-- title_emotion: string (nullable = true)\n |-- description_polarity: string (nullable = true)\n |-- description_emotion: string (nullable = true)\n |-- title_words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- description_words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- title_tfidf: vector (nullable = true)\n |-- description_tfidf: vector (nullable = true)\n |-- title_tfidf_features: vector (nullable = true)\n |-- description_tfidf_features: vector (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a479997-3969-4d79-a4fa-8b775e9933d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save the Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e591f760-802f-4534-928f-9bfb06ebc3af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into Gold table successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary view with only necessary columns for the gold layer\n",
    "final_df_gold = final_df.select(\n",
    "    \"post_id\",\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"subreddit\",\n",
    "    \"author\",\n",
    "    \"score\",\n",
    "    \"created_at\",\n",
    "    \"url\",\n",
    "    \"title_polarity\",\n",
    "    \"title_emotion\",\n",
    "    \"description_polarity\",\n",
    "    \"description_emotion\"\n",
    ")\n",
    "\n",
    "# Replace the temporary view with the cleaned DataFrame\n",
    "final_df_gold.createOrReplaceTempView(\"silver_reddit_posts_temp_gold\")\n",
    "\n",
    "# Insert data into the gold layer table from the cleaned DataFrame\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO big_data_analytics_v.big_data_analytics_sesssion_v.gold_reddit_posts\n",
    "    SELECT \n",
    "        post_id,\n",
    "        title,\n",
    "        description,\n",
    "        subreddit,\n",
    "        author,\n",
    "        score,\n",
    "        created_at,\n",
    "        url,\n",
    "        title_polarity,\n",
    "        title_emotion,\n",
    "        description_polarity,\n",
    "        description_emotion\n",
    "    FROM silver_reddit_posts_temp_gold\n",
    "\"\"\")\n",
    "\n",
    "# Log the completion of the insert process\n",
    "print(\"Data inserted into Gold table successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Sentiment Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}